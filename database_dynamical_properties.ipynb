{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from thom import *\n",
    "from thom.base import *\n",
    "from thom.utils import *\n",
    "from thom.analysis import *\n",
    "\n",
    "try:\n",
    "    from private.lyap import lyap_r, lyap_e, corr_dim\n",
    "except:\n",
    "    from nolds import lyap_r, lyap_e, corr_dim\n",
    "    \n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "Lorenz : Finished selecting initial points on attractor.\n",
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not enough arguments: expected 7, got 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-211e676ffb34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mall_estimates_lyap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_lyapunov_exponents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts_per_trajectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts_per_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts_per_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/program_repos/thom/thom/analysis.py\u001b[0m in \u001b[0;36mfind_lyapunov_exponents\u001b[0;34m(model, traj_length, pts_per_period)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \"\"\"\n\u001b[1;32m     47\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mtpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts_per_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpts_per_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/program_repos/thom/thom/base.py\u001b[0m in \u001b[0;36mmake_trajectory\u001b[0;34m(self, n, method, resample, pts_per_period, return_times)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0msol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintegrate_dyn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/program_repos/thom/thom/utils.py\u001b[0m in \u001b[0;36mintegrate_dyn\u001b[0;34m(f, ic, tvals, noise, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m#dt = np.median(np.diff(tvals))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0msol0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_ivp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m#sol = odeint(f, np.array(ic), tvals).T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nn/lib/python3.8/site-packages/scipy/integrate/_ivp/ivp.py\u001b[0m in \u001b[0;36msolve_ivp\u001b[0;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m     \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt_eval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nn/lib/python3.8/site-packages/scipy/integrate/_ivp/radau.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, t0, y0, t_bound, max_step, rtol, atol, jac, jac_sparsity, vectorized, first_step, **extraneous)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_max_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_tol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0;31m# Select initial step assuming the same order which is used to control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;31m# the error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nn/lib/python3.8/site-packages/scipy/integrate/_ivp/base.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nn/lib/python3.8/site-packages/scipy/integrate/_ivp/base.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/program_repos/thom/thom/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m#dt = np.median(np.diff(tvals))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0msol0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_ivp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0msol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/program_repos/thom/thom/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, t)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;34m\"\"\"Wrapper around right hand side\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     def make_trajectory(self, n, method=\"Radau\", resample=False, pts_per_period=100,\n",
      "\u001b[0;32m~/program_repos/thom/thom/base.py\u001b[0m in \u001b[0;36mrhs\u001b[0;34m(self, X, t)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"The right hand side of a dynamical equation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mparam_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rhs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparam_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: not enough arguments: expected 7, got 6"
     ]
    }
   ],
   "source": [
    "# We will make a local copy of the internal database\n",
    "OUTPUT_FILE = \"./chaotic_attractors2.json\"\n",
    "INPUT_FILE = \"thom/data/chaotic_attractors.json\"\n",
    "RECALCULATE = True\n",
    "\n",
    "points_to_sample = 2\n",
    "\n",
    "with open(INPUT_FILE, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "print(len(data.keys()))\n",
    "\n",
    "for i, item in enumerate(list(data.keys())):\n",
    "    \n",
    "    model = getattr(thom, item)()\n",
    "    \n",
    "    initial_sol = model.make_trajectory(1000, resample=True, pts_per_period=30)\n",
    "    sample_inds = np.random.choice(np.arange(initial_sol.shape[-1]), points_to_sample, replace=False)\n",
    "    sample_pts = initial_sol[:, sample_inds].T\n",
    "    model.ic = sample_pts\n",
    "    \n",
    "#     sol = model.make_trajectory(10000, resample=True, pts_per_period=300, method=\"RK45\")\n",
    "    tpts, sol = model.make_trajectory(5000, resample=True, pts_per_period=100, return_times=True)\n",
    "#     sol = model.make_trajectory(2000, method=\"Radau\", resample=True, pts_per_period=100)\n",
    "    dt = np.median(np.diff(tpts))\n",
    "    print(item, \": \", end=\"\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    points_to_sample = 10 # number of points to sample in ensemble\n",
    "    sample_pts = sample_initial_conditions(model, points_to_sample)\n",
    "    print(\"Finished selecting initial points on attractor.\")\n",
    "    pts_per_trajectory = 5000 # number of timesteps to use to find the jacobian\n",
    "    model.dt /= 10\n",
    "    \n",
    "    all_estimates_lyap = list()\n",
    "    all_estimates_corrdim = list()\n",
    "    for j, sample_pt in enumerate(sample_pts):\n",
    "        if j % 5 == 0: print(j)\n",
    "        model.ic = sample_pt\n",
    "        \n",
    "        all_estimates_lyap.append(find_lyapunov_exponents(model, pts_per_trajectory, pts_per_period=500))\n",
    "        \n",
    "        sol = model.make_trajectory(5000, resample=True, pts_per_period=100)\n",
    "        all_estimates_corrdim.append(corr_dim(sol))\n",
    "        \n",
    "    lyap = np.mean(np.array(all_estimates_lyap), axis=0)\n",
    "    cdim = np.mean(all_estimates_corrdom)\n",
    "    \n",
    "    if \"maximum_lyapunov_estimated\" not in data[item] or RECALCULATE:\n",
    "#         lyap = np.mean([lyap_r(item, tau=dt) for item in sol])\n",
    "#         lyap = lyap_r(sol[0, :, 0], tau=dt)\n",
    "        data[item][\"maximum_lyapunov_estimated\"] = lyap\n",
    "        print(f\"lyap: {lyap} \", end=\"\")\n",
    "    \n",
    "    if \"correlation_dimension\" not in data[item] or RECALCULATE:\n",
    "#         cdim = np.mean([corr_dim(item) for item in sol])\n",
    "        data[item][\"correlation_dimension\"] = cdim\n",
    "        print(f\"corr_dim: {cdim} \", end=\"\")\n",
    "    \n",
    "#     if \"permutation_entropy\" not in data[item] or RECALCULATE:\n",
    "        \n",
    "        \n",
    "    print(\"\\n\")\n",
    "    # Save new file\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "#     eq = getattr(thom, item)()\n",
    "#     sol = eq.make_trajectory(total_length, method=\"Radau\")\n",
    "    \n",
    "# #     all_freqs = list()\n",
    "# #     for comp in sol:\n",
    "# #         try:\n",
    "# #             freqs, amps = find_significant_frequencies(comp, return_amplitudes=True, significance_threshold=0.95)\n",
    "# #             max_freq = freqs[np.argmax(np.abs(amps))]\n",
    "# #         except:\n",
    "# #             ## ignores time-like coordinates\n",
    "# #             continue\n",
    "# #         all_freqs.append(max_freq)\n",
    "# #         print(\".\", end='')\n",
    "# #     period = eq.dt * (1 / np.median(all_freqs))\n",
    "    \n",
    "# #     freqs, amps = find_significant_frequencies(sol[0], return_amplitudes=True, significance_threshold=0.95)\n",
    "# #     max_freq = freqs[np.argmax(np.abs(amps))]\n",
    "# #     period = (1/max_freq) * eq.dt\n",
    "    \n",
    "#     #period = np.median([1/freq_from_fft(item) * eq.dt for item in sol])\n",
    "    \n",
    "#     data[item][\"period\"] = signif(period, 5)\n",
    "#     print(item, \" time period\", period,\" index period\", period/eq.dt, \" \", (1/eq.dt)/period)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pts_per_trajectory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-efdf8984cf70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpts_per_trajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pts_per_trajectory' is not defined"
     ]
    }
   ],
   "source": [
    "pts_per_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ti\n"
     ]
    }
   ],
   "source": [
    "print(\"t\", end=\"\")\n",
    "print(\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "t\n",
      "y\n",
      "t\n",
      "y\n",
      "t\n",
      "y\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(4):\n",
    "    if True:\n",
    "        pass\n",
    "        print(\"y\")\n",
    "\n",
    "    print(\"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sigma': 10, 'rho': 28, 'beta': 2.667}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6666666666666665"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9058,  0.0000, -14.572 for these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from private.lyap import *\n",
    "def delay_embedding(data, emb_dim, lag=1):\n",
    "  data = np.asarray(data)\n",
    "  min_len = (emb_dim - 1) * lag + 1\n",
    "  if len(data) < min_len:\n",
    "    msg = \"cannot embed data of length {} with embedding dimension {} \" \\\n",
    "        + \"and lag {}, minimum required length is {}\"\n",
    "    raise ValueError(msg.format(len(data), emb_dim, lag, min_len))\n",
    "  m = len(data) - min_len + 1\n",
    "  indices = np.repeat([np.arange(emb_dim) * lag], m, axis=0)\n",
    "  indices += np.arange(m).reshape((m, 1))\n",
    "  return data[indices]\n",
    "def lyap_r(data, emb_dim=10, lag=None, min_tsep=None, tau=1, min_neighbors=20,\n",
    "           trajectory_len=20, fit=\"RANSAC\", debug_plot=False, debug_data=False,\n",
    "           plot_file=None, fit_offset=0):\n",
    "  \"\"\"\n",
    "  Estimates the largest Lyapunov exponent using the algorithm of Rosenstein\n",
    "  et al. [lr_1]_.\n",
    "  Explanation of Lyapunov exponents:\n",
    "    See lyap_e.\n",
    "  Explanation of the algorithm:\n",
    "    The algorithm of Rosenstein et al. is only able to recover the largest\n",
    "    Lyapunov exponent, but behaves rather robust to parameter choices.\n",
    "    The idea for the algorithm relates closely to the definition of Lyapunov\n",
    "    exponents. First, the dynamics of the data are reconstructed using a delay\n",
    "    embedding method with a lag, such that each value x_i of the data is mapped\n",
    "    to the vector\n",
    "    X_i = [x_i, x_(i+lag), x_(i+2*lag), ..., x_(i+(emb_dim-1) * lag)]\n",
    "    For each such vector X_i, we find the closest neighbor X_j using the\n",
    "    euclidean distance. We know that as we follow the trajectories from X_i and\n",
    "    X_j in time in a chaotic system the distances between X_(i+k) and X_(j+k)\n",
    "    denoted as d_i(k) will increase according to a power law\n",
    "    d_i(k) = c * e^(lambda * k) where lambda is a good approximation of the\n",
    "    highest Lyapunov exponent, because the exponential expansion along the axis\n",
    "    associated with this exponent will quickly dominate the expansion or\n",
    "    contraction along other axes.\n",
    "    To calculate lambda, we look at the logarithm of the distance trajectory,\n",
    "    because log(d_i(k)) = log(c) + lambda * k. This gives a set of lines\n",
    "    (one for each index i) whose slope is an approximation of lambda. We\n",
    "    therefore extract the mean log trajectory d'(k) by taking the mean of\n",
    "    log(d_i(k)) over all orbit vectors X_i. We then fit a straight line to\n",
    "    the plot of d'(k) versus k. The slope of the line gives the desired\n",
    "    parameter lambda.\n",
    "  Method for choosing min_tsep:\n",
    "    Usually we want to find neighbors between points that are close in phase\n",
    "    space but not too close in time, because we want to avoid spurious\n",
    "    correlations between the obtained trajectories that originate from temporal\n",
    "    dependencies rather than the dynamic properties of the system. Therefore it\n",
    "    is critical to find a good value for min_tsep. One rather plausible\n",
    "    estimate for this value is to set min_tsep to the mean period of the\n",
    "    signal, which can be obtained by calculating the mean frequency using the\n",
    "    fast fourier transform. This procedure is used by default if the user sets\n",
    "    min_tsep = None.\n",
    "  Method for choosing lag:\n",
    "    Another parameter that can be hard to choose by instinct alone is the lag\n",
    "    between individual values in a vector of the embedded orbit. Here,\n",
    "    Rosenstein et al. suggest to set the lag to the distance where the\n",
    "    autocorrelation function drops below 1 - 1/e times its original (maximal)\n",
    "    value. This procedure is used by default if the user sets lag = None.\n",
    "  References:\n",
    "    .. [lr_1] M. T. Rosenstein, J. J. Collins, and C. J. De Luca,\n",
    "       “A practical method for calculating largest Lyapunov exponents from\n",
    "       small data sets,” Physica D: Nonlinear Phenomena, vol. 65, no. 1,\n",
    "       pp. 117–134, 1993.\n",
    "  Reference Code:\n",
    "    .. [lr_a] mirwais, \"Largest Lyapunov Exponent with Rosenstein's Algorithm\",\n",
    "       url: http://www.mathworks.com/matlabcentral/fileexchange/38424-largest-lyapunov-exponent-with-rosenstein-s-algorithm\n",
    "    .. [lr_b] Shapour Mohammadi, \"LYAPROSEN: MATLAB function to calculate\n",
    "       Lyapunov exponent\",\n",
    "       url: https://ideas.repec.org/c/boc/bocode/t741502.html\n",
    "  Args:\n",
    "    data (iterable of float):\n",
    "      (one-dimensional) time series\n",
    "  Kwargs:\n",
    "    emb_dim (int):\n",
    "      embedding dimension for delay embedding\n",
    "    lag (float):\n",
    "      lag for delay embedding\n",
    "    min_tsep (float):\n",
    "      minimal temporal separation between two \"neighbors\" (default:\n",
    "      find a suitable value by calculating the mean period of the data)\n",
    "    tau (float):\n",
    "      step size between data points in the time series in seconds\n",
    "      (normalization scaling factor for exponents)\n",
    "    min_neighbors (int):\n",
    "      if lag=None, the search for a suitable lag will be stopped when the\n",
    "      number of potential neighbors for a vector drops below min_neighbors\n",
    "    trajectory_len (int):\n",
    "      the time (in number of data points) to follow the distance\n",
    "      trajectories between two neighboring points\n",
    "    fit (str):\n",
    "      the fitting method to use for the line fit, either 'poly' for normal\n",
    "      least squares polynomial fitting or 'RANSAC' for RANSAC-fitting which\n",
    "      is more robust to outliers\n",
    "    debug_plot (boolean):\n",
    "      if True, a simple plot of the final line-fitting step will\n",
    "      be shown\n",
    "    debug_data (boolean):\n",
    "      if True, debugging data will be returned alongside the result\n",
    "    plot_file (str):\n",
    "      if debug_plot is True and plot_file is not None, the plot will be saved\n",
    "      under the given file name instead of directly showing it through\n",
    "      ``plt.show()``\n",
    "    fit_offset (int):\n",
    "      neglect the first fit_offset steps when fitting\n",
    "  Returns:\n",
    "    float:\n",
    "      an estimate of the largest Lyapunov exponent (a positive exponent is\n",
    "      a strong indicator for chaos)\n",
    "    (1d-vector, 1d-vector, list):\n",
    "      only present if debug_data is True: debug data of the form\n",
    "      ``(ks, div_traj, poly)`` where ``ks`` are the x-values of the line fit, \n",
    "      ``div_traj`` are the y-values and ``poly`` are the line coefficients\n",
    "      (``[slope, intercept]``).\n",
    "  \"\"\"\n",
    "  # convert data to float to avoid overflow errors in rowwise_euclidean\n",
    "  data = np.asarray(data, dtype=\"float32\")\n",
    "  n = len(data)\n",
    "  max_tsep_factor = 0.25\n",
    "  if lag is None or min_tsep is None:\n",
    "    # both the algorithm for lag and min_tsep need the fft\n",
    "    f = np.fft.rfft(data, n * 2 - 1)\n",
    "  if min_tsep is None:\n",
    "    # calculate min_tsep as mean period (= 1 / mean frequency)\n",
    "    mf = np.fft.rfftfreq(n * 2 - 1) * np.abs(f)\n",
    "    mf = np.mean(mf[1:]) / np.sum(np.abs(f[1:]))\n",
    "    min_tsep = int(np.ceil(1.0 / mf))\n",
    "    if min_tsep > max_tsep_factor * n:\n",
    "      min_tsep = int(max_tsep_factor * n)\n",
    "      msg = \"signal has very low mean frequency, setting min_tsep = {:d}\"\n",
    "      warnings.warn(msg.format(min_tsep), RuntimeWarning)\n",
    "  if lag is None:\n",
    "    # calculate the lag as point where the autocorrelation drops to (1 - 1/e)\n",
    "    # times its maximum value\n",
    "    # note: the Wiener–Khinchin theorem states that the spectral\n",
    "    # decomposition of the autocorrelation function of a process is the power\n",
    "    # spectrum of that process\n",
    "    # => we can use fft to calculate the autocorrelation\n",
    "    acorr = np.fft.irfft(f * np.conj(f))\n",
    "    acorr = np.roll(acorr, n - 1)\n",
    "    eps = acorr[n - 1] * (1 - 1.0 / np.e)\n",
    "    lag = 1\n",
    "    # small helper function to calculate resulting number of vectors for a\n",
    "    # given lag value\n",
    "    def nb_neighbors(lag_value):\n",
    "      min_len = lyap_r_len(\n",
    "        emb_dim=emb_dim, lag=i, trajectory_len=trajectory_len,\n",
    "        min_tsep=min_tsep\n",
    "      )\n",
    "      return max(0, n - min_len)\n",
    "    # find lag\n",
    "    for i in range(1,n):\n",
    "      lag = i\n",
    "      if acorr[n - 1 + i] < eps or acorr[n - 1 - i] < eps:\n",
    "        break\n",
    "      if nb_neighbors(i) < min_neighbors:\n",
    "        msg = \"autocorrelation declined too slowly to find suitable lag\" \\\n",
    "          + \", setting lag to {}\"\n",
    "        warnings.warn(msg.format(lag), RuntimeWarning)\n",
    "        break\n",
    "  min_len = lyap_r_len(\n",
    "    emb_dim=emb_dim, lag=lag, trajectory_len=trajectory_len,\n",
    "    min_tsep=min_tsep\n",
    "  )\n",
    "  if len(data) < min_len:\n",
    "    msg = \"for emb_dim = {}, lag = {}, min_tsep = {} and trajectory_len = {}\" \\\n",
    "      + \" you need at least {} datapoints in your time series\"\n",
    "    warnings.warn(\n",
    "      msg.format(emb_dim, lag, min_tsep, trajectory_len, min_len),\n",
    "      RuntimeWarning\n",
    "    )\n",
    "  # delay embedding\n",
    "  orbit = delay_embedding(data, emb_dim, lag)\n",
    "  m = len(orbit)\n",
    "  # construct matrix with pairwise distances between vectors in orbit\n",
    "  dists = np.array([rowwise_euclidean(orbit, orbit[i]) for i in range(m)])\n",
    "  # we do not want to consider vectors as neighbor that are less than min_tsep\n",
    "  # time steps together => mask the distances min_tsep to the right and left of\n",
    "  # each index by setting them to infinity (will never be considered as nearest\n",
    "  # neighbors)\n",
    "  for i in range(m):\n",
    "    dists[i, max(0, i - min_tsep):i + min_tsep + 1] = float(\"inf\")\n",
    "  # check that we have enough data points to continue\n",
    "  ntraj = m - trajectory_len + 1\n",
    "  min_traj = min_tsep * 2 + 2 # in each row min_tsep + 1 disances are inf\n",
    "  if ntraj <= 0:\n",
    "    msg = \"Not enough data points. Need {} additional data points to follow \" \\\n",
    "        + \"a complete trajectory.\"\n",
    "    raise ValueError(msg.format(-ntraj+1))\n",
    "  if ntraj < min_traj:\n",
    "    # not enough data points => there are rows where all values are inf\n",
    "    assert np.any(np.all(np.isinf(dists[:ntraj, :ntraj]), axis=1))\n",
    "    msg = \"Not enough data points. At least {} trajectories are required \" \\\n",
    "        + \"to find a valid neighbor for each orbit vector with min_tsep={} \" \\\n",
    "        + \"but only {} could be created.\"\n",
    "    raise ValueError(msg.format(min_traj, min_tsep, ntraj))\n",
    "  assert np.all(np.any(np.isfinite(dists[:ntraj, :ntraj]), axis=1))\n",
    "  # find nearest neighbors (exclude last columns, because these vectors cannot\n",
    "  # be followed in time for trajectory_len steps)\n",
    "  nb_idx = np.argmin(dists[:ntraj, :ntraj], axis=1)\n",
    "  \n",
    "  # build divergence trajectory by averaging distances along the trajectory\n",
    "  # over all neighbor pairs\n",
    "  div_traj = np.zeros(trajectory_len, dtype=float)\n",
    "  for k in range(trajectory_len):\n",
    "    # calculate mean trajectory distance at step k\n",
    "    indices = (np.arange(ntraj) + k, nb_idx + k)\n",
    "    div_traj_k = dists[indices]\n",
    "    # filter entries where distance is zero (would lead to -inf after log)\n",
    "    nonzero = np.where(div_traj_k != 0)\n",
    "    if len(nonzero[0]) == 0:\n",
    "      # if all entries where zero, we have to use -inf\n",
    "      div_traj[k] = -np.inf\n",
    "    else:\n",
    "      div_traj[k] = np.mean(np.log(div_traj_k[nonzero]))\n",
    "  # filter -inf entries from mean trajectory\n",
    "  ks = np.arange(trajectory_len)\n",
    "  finite = np.where(np.isfinite(div_traj))\n",
    "  ks = ks[finite]\n",
    "  div_traj = div_traj[finite]\n",
    "  if len(ks) < 1:\n",
    "    # if all points or all but one point in the trajectory is -inf, we cannot\n",
    "    # fit a line through the remaining points => return -inf as exponent\n",
    "    poly = [-np.inf, 0]\n",
    "  else:\n",
    "    # normal line fitting\n",
    "    poly = poly_fit(ks[fit_offset:], div_traj[fit_offset:], 1, fit=fit)\n",
    "  if debug_plot:\n",
    "    plot_reg(ks[fit_offset:], div_traj[fit_offset:], poly, \"k\", \"log(d(k))\", fname=plot_file)\n",
    "  le = poly[0] / tau\n",
    "  if debug_data:\n",
    "    return (le, (ks, div_traj, poly))\n",
    "  else:\n",
    "    return le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

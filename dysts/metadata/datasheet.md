### Dataset documentation and datasheet

A dataset nutrition label reports metadata and relevant summary statistics for all datasets. The notebook ['nutrition_label.ipynb'](nutrition_label.ipynb) includes examples for retrieving metadata from each dynamical system, as well as computing relevant summary statistics.

Here we address the questions included in the appendix of [Gebru et al.](https://arxiv.org/abs/1803.09010)



### Motivation

**Purpose** This dataset was created for the purpose of providing a generative benchmark for time series mining applications, in which arbitrary synthetic data can be generated using a deterministic process.

**Unintended Uses** To our knowledge, there are no clear uses for this data that could cause unintended harm. However, if any users become aware of any potential risks, we encourage notifying us by submitting an issue on GitHub.

**Previous Uses** Parts of this repository were used in our previous work [Gilpin NeurIPS 2020](https://arxiv.org/abs/2002.05909), but the full dataset and benchmarks are all new. 

**Creator and Funding.** This repository was created by William Gilpin, with support from the NSF-Simons Center for Quantitative Biology at Harvard University, as well as the University of Texas at Austin. No special funding was solicited for this particular project.



### Composition

**Instances.** Each instance in this dataset comprises a set of nonlinear differential equations describing a chaotic process, a set of standard parameter values and initial conditions, a citation to a published source (when available), and an example trajectory generated by the system

**Instance Relationships.** Each instance corresponds to a different dynamical system.

**Instance Count.** At time of writing, there are 131 continuous-time dynamical systems (126 ordinary differential equations, and 5 delay equations). There are also 30 discrete-time chaotic maps.

**Instance Scope.** Each instance corresponds to a particular realization of a dynamical system, based on previously-published parameter values and initial conditions. In principle, an infinite number of additional chaotic systems exists; our dataset seeks to provide a representative sample of published systems.

**Labels.** Each trajectory and system contains metadata describing its provenance, however there is not a particular label associated with each trajectory. Certain special classes of systems with special mathematical properties have additional fields in their metadata, which could be used as labels, such as `hamiltonian` or `nonautonomous`

**External Dependencies.** The data itself has no external dependencies. Simulating each system requires several standard scientific Python packages (enumerated in the repository README file). Running the benchmark requires several additional dependencies, which are also listed in the README.

**Data Splits.** No splits are baked-in, because (in principle) arbitrary amounts of training, validation, and testing data can be generated for each dynamical system. Splits can either be performed by holding out some timepoints, or (for multivariate systems) by splitting the set of dynamical variables. For the purpose of benchmarking experiments, splits corresponding to $10$ periods of training data, and $2$ periods of unseen prediction/validation data, were used for both the train and test datasets (the test dataset corresponds to an unseen initial condition). For the fine granularity time series, this corresponds to splits of 1000/200 for both the train and test initial conditions. For the coarse granularity time series, this corresponds to a split of 150/30.

**Experiments.** All benchmark experiments are described at length in our preprint. They primarily consist of forecasting benchmarks, generative experiments (importance sampling and model pretraining), and data-driven model inference experiments.



### Collection

**Collection.** Systems were manually identified based on their appearance in published works after 1965. Systems were only included that had (1) explicit analytical expressions and (2) published parameter values and initial conditions leading to chaos. All systems required manual implementation and verification that the claimed dynamics were chaotic.

**Workers.** All individuals involved in data collection and curation are authors on the paper.

**Timeframe.** Data was gradually collected from 2018 - 2021.

**Instance Acquisition.** Each dynamical system required implementation in Python of the stated dynamical equations, as well as all parameter values and initial conditions leading to chaos. Each system was then numerically integrated in order to ensure that the observed dynamics matched those claimed in the original publication. Once chaos was validated, the integration timestep and the trajectory sampling rate were determined using the power spectrum, with time series surrogate analysis used to identify significant frequencies. Once the correct timescales were known, properties such as the Lyapunov exponents and entropy were calculated. For all trajectory data and initial conditions, a long transient was discarded in order to ensure that the dynamics settled onto the attractor.

**Instance Scope.** There are effectively an infinite number of possible chaotic dynamical systems, even in low dimensions. However, our collection represents a sample of named and published chaotic systems, and it includes most well-known systems.

**Sampling.** Because our dataset comprises only named and published chaotic systems, it does not comprise a representative sample of the larger space of all low-dimensional chaotic systems. Therefore, our database should not be used to compute any quantities that depend on the measure of chaotic systems within the broader space of all possible dynamical systems. For example, a study that seeks to identify the most common features or motifs of chaotic systems cannot use our database as representative sample. However, our database does comprise a representative sample of chaotic dynamics as they appear in the literature.

**Missing Information.** For systems in which a reference citation or additional context is unavailable, the corresponding field in the metadata file is left blank. However, all systems have sufficient information to be integrated.

**Errors and Noise.** If any errors or redundancies are identified, we encourage users to submit an issue via GitHub. Noise can be added to the trajectories either by adding random values to each observed timepoint (ie measurement noise), or performing a stochastic simulation (ie stochastic dynamics)




### Preprocessing

**Cleaning.** Dynamical systems may be numerically integrated with arbitrary precision, and their dynamics can be recorded at arbitrarily small intervals. In order to report all systems consistently, we use time series surrogate testing to identify the highest significant frequency in the power spectrum of each system's dynamics. We then set the numerical integration timestep to be proportional to this timescale. We then re-integrate, and use surrogates to identify the dominant significant frequency in each system's dynamics. We use this timescale to determine the sampling rate. This process ensures overall that all systems exhibit dynamical variation over comparable timescales, and that the integration timestep is sufficiently small to accurately resolve the dynamics.

Having determined the appropriate integration timescales, we then determine the Lyapunov exponents, average period, and other ensemble-level properties of each dynamical system. We compute these quantities for replicate trajectories originating from different initial conditions on the attractor, and record the average.

For each fixed univariate time series dataset, the first ordinal component of the system's dynamics is included.

**Raw data.** New time series data can be generated as needed via the `make_trajectory()` method of each dynamical system.

**Preprocessing Software.** All analysis software is included in the repository.

**Motivation.** To our knowledge, dataset processing is consistent with the underlying motivation of the dataset.



### Distribution

**Distribution.** The dataset is distributed on GitHub.

**First Distribution.** A private fork is distributed with the paper for review in order to maintain anonymity for certain venues. The updated repository will be distributed with the final paper.

**License.** We include an Apache 2.0 License in the project repository.

**Fees.** None.



### Legal

**People.** No individuals are included in this dataset.

**Protected Subjects.** No ethically-protected subjects are included in this dataset.

**Institutional Approval.** No institutional approval is required for this dataset

**Consent.** No individual data is included in this dataset.

**Harm.** No individual data is included in this dataset.

**Disadvantages.** No individual data is included in this dataset.

**Privacy.** None of the data contains personal information.

**GDPR.** To our knowledge, this dataset complies with GDPR and equivalent foreign standards.

**Sensitivity.** To our knowledge, this dataset contains no sensitive information

**Inappropriate.** This dataset contains no inappropriate or offensive content.


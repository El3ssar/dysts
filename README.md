# dysts

Simulate hundreds of chaotic systems.


## Usage


Import a model and run a simulation with default initial conditions and parameter values

```python
from dysts.flows import Lorenz
```

model = Lorenz()
sol = model.make_trajectory(1000)
    
Load a precomputed collection of time series

```python
from dysts.datasets import load_continuous

series_train = load_continuous().to_array(standardize=True)
#plt.imshow(series_train[:, :200])
```
   
Modify a model's parameter values

```python
model = Lorenz()
model.gamma = 1
model.ic = [0, 0, 0.2]
sol = model.make_trajectory(1000)
```
    
Additional functionality and examples can be found in [`the demonstrations notebook.`](demos.ipynb)

## Installation

Install locally from GitHub

    pip install pip install git+git://github.com/williamgilpin/dysts

Various key dependencies are the following

+ Python >3.0
+ numpy

These optional dependencies are needed for various specific tasks included in this repo, such as benchmarking

+ numba (speeds up generation of trajectories)
+ nolds (used for calculating the correlation dimension)
+ sdeint (used for adding noise to dynamics)
+ darts (used for benchmarking)
+ tsfresh (used for embedding time series)


## Contributing

If you know of any systems should be included, please feel free to submit an issue or pull request. The biggest bottleneck when adding new models is a lack of known parameter values and initial conditions, and so please provide a reference or code that contains all parameter values necessary to reproduce the claimed dynamics.

## Contents

+ Definitions and metadata for all chaotic systems are included in the database [`chaotic_attractors`](dysts/dysts/data/chaotic_attractors.json)
+ Code to generate benchmark forecasting and training experiments are included in [`benchmarks`](dysts/benchmarks)
+ + All benchmark results and metrics are included in [`benchmarks/results`](dysts/benchmarks/results)
+ + Fitted hyperparameters for each dynamical system and forecasting model are included in [`benchmarks/hyperparameters`](dysts/benchmarks/hyperparameters)
+ Pre-computed time series with training and test partitions are included in [`data`](dysts/dysts/data)

## Implementation Notes

+ Currently there are ~200 models, including ~110 continuous-time ordinary differential equations, ~30 discrete maps, and ~10 delay differential equations.
+ The right hand side of each dynamical equation is compiled using `numba`, wherever possible. Ensembles of trajectories are vectorized  when possible
+ Attractor names, default parameter values, references, and other metadata are stored in parseable JSON database files. Parameter values are based on standard or published values, and default initial conditions were generated by running each model until the moments of the autocorrelation function all become stationary.
+ The default integration step is stored in each continuous-time model's `dt` field. This integration timestep was chosen based on the highest significant frequency observed in the power spectrum, with significance being determined relative to [surrogate time series](https://en.wikipedia.org/wiki/Surrogate_data_testing). The `period` field contains the timescale associated with the dominant frequency in each system's power spectrum.When using the `model.make_trajectory` method, integration is performed at the default `dt`. The integrated trajectory is then resampled based on the `period`. The resulting trajectories will have have consistant domant timescales across models, despite having different integration timesteps.

## Acknowledgements

+ Two existing databases of named systems can be found on the webpages of [J&uuml;rgen Meier](http://www.3d-meier.de/tut19/Seite1.html) and [J. C. Sprott](http://sprott.physics.wisc.edu/sprott.htm). The current version of `dysts` contains all continuous systems from both collections.
+ Several of the analysis routines (such as calculation of the correlation dimension) use the library [nolds](https://github.com/CSchoel/nolds). If re-using any code that depends on `nolds`, please be sure to credit that library and heed its license. The Lyapunov exponent calculation is based on the QR factorization approach used by [Wolf et al 1985](https://www.sciencedirect.com/science/article/abs/pii/0167278985900119) and [Eckmann et al 1986](https://journals.aps.org/pra/abstract/10.1103/PhysRevA.34.4971), with implementation details adapted from conventions in the Julia library [DynamicalSystems.jl](https://github.com/JuliaDynamics/DynamicalSystems.jl/)


## Ethics & Reporting

Dataset datasheets and metadata are reported using standard dataset documentation guidelines; see the [`dataset datasheet`](dysts/metadata/datasheet.md)
All datasets included here are mathematical in nature, and do not contain human or clinical observations.


## Development to-do list

A partial list of improvements in future versions

+ Finish making all differential equations compilable
+ Speed up the delay equation implementation
+ Vectorize multiple initial conditions for continuous time models
+ Add a separate jacobian database, and add an attribute that can be used to check if an analytical one exists. This will speed up numerical integration, as well as potentially aid in calculating Lyapunov exponents, etc.
+ Align the initial phases, potentially by picking default starting initial conditions that lie on the attractor, but which are as close as possible to the origin
+ Add a `dimension` field with the number of dynamical variables
+ The advantage of maps are that they are deterministic but not differentiable
+ Add a module for simulating several models at once via multiprocessing



